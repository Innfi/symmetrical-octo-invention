>[!question]
>Model Architecture?

- adoping neural attention to create a sequence model
- context awareness: determine which part to pay attention
## Self Attention
- [[Self Attention]]
## Multi Head Attention
- [[Multi Head Attention]]

## Transformer Encoder
- [[Transformer-Encoder]]

## Transformer Decoder


![](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)


## Terms
- sequence - to sequence learning
- positional encoding
- transformer decoder
- causal padding
